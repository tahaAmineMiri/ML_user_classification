{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "968f6584",
   "metadata": {},
   "source": [
    "# Importing the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df416b8a",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434aead",
   "metadata": {},
   "source": [
    "### Importing the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c620a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from the CSV file\n",
    "raw_data = pd.read_csv('ml_datasource.csv')\n",
    "\n",
    "# Display the first 5 rows of the dataframe for preview\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4580c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ab2c7",
   "metadata": {},
   "source": [
    "### Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset any modifications to the plotting context (sns) made via seaborn\n",
    "sns.reset_orig()\n",
    "\n",
    "# Set the font scale for seaborn plots\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Initialize a grid of plots with specified dimensions\n",
    "fig, axes = plt.subplots(3, 2, figsize=(20,20))\n",
    "\n",
    "# Plotting distribution plots for each of the columns in the dataset\n",
    "sns.kdeplot(data=data['days_on_platform'], ax=axes[0,0])\n",
    "sns.kdeplot(data=data['minutes_watched'], ax=axes[0,1])\n",
    "sns.kdeplot(data=data['courses_started'], ax=axes[1,0])\n",
    "sns.kdeplot(data=data['practice_exams_started'], ax=axes[1,1])\n",
    "sns.kdeplot(data=data['practice_exams_passed'], ax=axes[2,0])\n",
    "sns.kdeplot(data=data['minutes_spent_on_exams'], ax=axes[2,1]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers based on 'minutes_watched', 'courses_started',\n",
    "# and 'practice_exams_started', and 'minutes_spent_on_exams' fields\n",
    "data_no_outliers = data[(data['minutes_watched'] <= 1000)\n",
    "                            & (data['courses_started']<=10)\n",
    "                            & (data['practice_exams_started']<=10)\n",
    "                            & (data['minutes_spent_on_exams']<=40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecce72e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reset any modifications to the plotting context (sns) made via seaborn\n",
    "sns.reset_orig()\n",
    "\n",
    "# Set the font scale for seaborn plots\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Initialize a grid of plots with specified dimensions\n",
    "fig, axes = plt.subplots(3, 2, figsize=(20,20))\n",
    "\n",
    "# Plotting distribution plots for each of the columns in the dataset\n",
    "sns.kdeplot(data=data_no_outliers['days_on_platform'], ax=axes[0,0])\n",
    "sns.kdeplot(data=data_no_outliers['minutes_watched'], ax=axes[0,1])\n",
    "sns.kdeplot(data=data_no_outliers['courses_started'], ax=axes[1,0])\n",
    "sns.kdeplot(data=data_no_outliers['practice_exams_started'], ax=axes[1,1])\n",
    "sns.kdeplot(data=data_no_outliers['practice_exams_passed'], ax=axes[2,0])\n",
    "sns.kdeplot(data=data_no_outliers['minutes_spent_on_exams'], ax=axes[2,1]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9cc4a7",
   "metadata": {},
   "source": [
    "### Checking for Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the column names of the dataset (for reference)\n",
    "data_no_outliers.columns.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228bb4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the numerical columns for Variance Inflation Factor (VIF) calculation\n",
    "variables = data_no_outliers[['days_on_platform',\n",
    "                              'minutes_watched',\n",
    "                              'courses_started', \n",
    "                              'practice_exams_started', \n",
    "                              'practice_exams_passed', \n",
    "                              'minutes_spent_on_exams']]\n",
    "\n",
    "# Creating a DataFrame to store the VIF value for each feature\n",
    "vif = pd.DataFrame()\n",
    "\n",
    "# Computing the VIF for each selected feature using list comprehension\n",
    "# Storing the values in a column called 'VIF'\n",
    "vif['VIF'] = [variance_inflation_factor(variables.to_numpy(), i) for i in range(variables.shape[1])]\n",
    "\n",
    "# Storing the names of the features in a column called 'features'\n",
    "vif['features'] = variables.columns\n",
    "\n",
    "# Displaying the DataFrame\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd8ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping 'practice_exams' to prevent multicollinearity \n",
    "data_no_mult = data_no_outliers.drop('practice_exams_started', axis = 1)\n",
    "\n",
    "# Displaying the first five rows of the new data\n",
    "data_no_mult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd54128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specific columns for new Variance Inflation Factor (VIF) calculation\n",
    "variables = data_no_outliers[['days_on_platform',\n",
    "                              'minutes_watched',\n",
    "                              'courses_started', \n",
    "                              'practice_exams_passed', \n",
    "                              'minutes_spent_on_exams']]\n",
    "\n",
    "# Computing the new VIF values for each selected feature\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF\"] = [variance_inflation_factor(variables.to_numpy(), i) for i in range(variables.shape[1])]\n",
    "vif[\"features\"] = variables.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1e168",
   "metadata": {},
   "source": [
    "### Dealing with NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of null values in each column\n",
    "data_no_mult.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a9d87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select rows from the 'data_no_mult' DataFrame where the \n",
    "# 'student_country' column has missing values (NaN).\n",
    "data_no_mult.loc[ data_no_mult['student_country'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b231a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing NaN values with the string 'NAM'\n",
    "data_no_nulls = data_no_mult.fillna('NAM', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c691c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying records where 'student_country' is 'NAM'\n",
    "data_no_nulls.loc[ data_no_nulls['student_country'] == 'NAM', 'student_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-checking the number of null values in each column after replacement\n",
    "data_no_nulls.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c7040a",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b8b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining inputs (feature variables) and target (outcome variable)\n",
    "inputs = data_no_nulls.drop(['purchased'],axis=1)\n",
    "target = data_no_nulls['purchased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets, ensuring balanced classes with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, \n",
    "                                                    target, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=365,\n",
    "                                                    stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the DataFrame for preview\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced87b59",
   "metadata": {},
   "source": [
    "### Encoding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c5791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing an ordinal encoder for categorical variables\n",
    "enc = OrdinalEncoder(handle_unknown = 'use_encoded_value', \n",
    "                     unknown_value = 170);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3790879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the 'student_country' column in the training and testing datasets\n",
    "# and storing the encoded variable in a new column called 'student_country_enc'\n",
    "x_train['student_country_enc'] = enc.fit_transform(x_train['student_country'].to_numpy().reshape(-1, 1));\n",
    "x_test['student_country_enc'] = enc.transform(x_test['student_country'].to_numpy().reshape(-1, 1));\n",
    "\n",
    "# Dropping the original 'student_country' column after encoding\n",
    "x_train = x_train.drop('student_country', axis = 1)\n",
    "x_test = x_test.drop('student_country', axis = 1)\n",
    "\n",
    "# Displaying the first five rows of the encoded training dataset\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbc3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the np.asarray() method to ensure data type consistency and compatibility.\n",
    "# y_train values are converted to integers and x_train values are converted to floating-point numbers.\n",
    "\n",
    "x_train_array = np.asarray(x_train, dtype = 'float')\n",
    "y_train_array = np.asarray(y_train, dtype = 'int')\n",
    "\n",
    "x_test_array = np.asarray(x_test, dtype = 'float')\n",
    "y_test_array = np.asarray(y_test, dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50436b36",
   "metadata": {},
   "source": [
    "# Creating a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e88380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a logistic regression model using the sm.Logit function\n",
    "log_reg = sm.Logit(y_train_array, x_train_array)\n",
    "\n",
    "# Fitting the model to the training data\n",
    "log_reg_results = log_reg.fit()\n",
    "\n",
    "# Displaying a summary of the model results\n",
    "log_reg_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108ecdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions on the test set and rounding the predictions to nearest integer (0 or 1)\n",
    "y_test_pred_log_reg = [round(log_reg_results.predict(x_test_array)[i], 0) \n",
    "                       for i in range(len(y_test_array))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f82c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting any modifications to the plotting context made via seaborn\n",
    "sns.reset_orig()\n",
    "\n",
    "# Displaying the confusion matrix from the model's predictions;\n",
    "# 'magma' colormap is used for better visualization of the matrix;\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test_array, y_test_pred_log_reg,\n",
    "    cmap = 'magma'\n",
    ");\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d10db71",
   "metadata": {},
   "source": [
    "# Creating a K-Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2352fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for the grid search\n",
    "parameters_knn = {'n_neighbors':range(1, 51), \n",
    "                  'weights':['uniform', 'distance']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a585e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a GridSearchCV object with KNeighborsClassifier estimator\n",
    "# and accuracy as the scoring metric\n",
    "grid_search_knn = GridSearchCV(estimator = KNeighborsClassifier(), \n",
    "                               param_grid = parameters_knn, \n",
    "                               scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc88ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search object on the training data\n",
    "grid_search_knn.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ed9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best parameters and the corresponding score\n",
    "grid_search_knn.best_params_, grid_search_knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ba50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the best estimator (model with optimal parameters) in knn_clf\n",
    "knn_clf = grid_search_knn.best_estimator_\n",
    "\n",
    "# Display the model\n",
    "knn_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42172aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target variable for the test dataset using the optimal model\n",
    "y_test_pred_knn = knn_clf.predict(x_test_array)\n",
    "\n",
    "# Reset seaborn settings to default\n",
    "sns.reset_orig()\n",
    "\n",
    "# Display the confusion matrix using seaborn;\n",
    "# Set the labels to the classes of the model;\n",
    "# Choose the magma colormap for better visualization\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test_array, y_test_pred_knn,\n",
    "    labels = knn_clf.classes_,\n",
    "    cmap = 'magma' \n",
    ");\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9924f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report, providing an overview of how well the classifier has performed\n",
    "print(classification_report(y_test_array, \n",
    "                            y_test_pred_knn, \n",
    "                            target_names = ['0', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aa87a4",
   "metadata": {},
   "source": [
    "# Creating a Support Vector Machines Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a392bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the MinMaxScaler. This will normalize the features to a range between -1 and 1\n",
    "scaling = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "# Fit the scaler to the training data and transform it\n",
    "x_train_array_svc = scaling.fit_transform(x_train_array)\n",
    "\n",
    "# Use the same scaler to transform the test data\n",
    "x_test_array_svc = scaling.transform(x_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dictionary of parameters for grid search\n",
    "parameters_svc = {'kernel':['linear', 'poly', 'rbf'], \n",
    "                  'C':range(1, 11),\n",
    "                  'gamma': ['scale', 'auto']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a GridSearchCV object with the SVC estimator and accuracy as the scoring metric\n",
    "grid_search_svc = GridSearchCV(estimator = SVC(), \n",
    "                               param_grid = parameters_svc, \n",
    "                               scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b1c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Fitting process can take some time due to the number of combinations\n",
    "grid_search_svc.fit(x_train_array_svc, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best model obtained from the grid search\n",
    "grid_search_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1c3c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the best estimator (model with optimal parameters) in svc_clf\n",
    "svc_clf = grid_search_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best estimator to predict the target variable for the test dataset\n",
    "y_test_pred_svc = svc_clf.predict(x_test_array_svc)\n",
    "\n",
    "# Reset seaborn settings to default\n",
    "sns.reset_orig()\n",
    "\n",
    "# Display the confusion matrix using seaborn;\n",
    "# Use 'magma' colormap for better visualization\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test_array, y_test_pred_svc,\n",
    "    labels = svc_clf.classes_,\n",
    "    cmap = 'magma'\n",
    ");\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08818e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report to get precision, recall, f1-score, and support for each class\n",
    "print(classification_report(y_test_array, \n",
    "                            y_test_pred_svc, \n",
    "                            target_names = ['0', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172bf1f1",
   "metadata": {},
   "source": [
    "# Creating a Decision Trees Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530fbc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the GridSearch. \n",
    "# Here we're trying different values for the ccp_alpha parameter\n",
    "parameters_dt = {'ccp_alpha':[0, \n",
    "                              0.001, \n",
    "                              0.002, \n",
    "                              0.003, \n",
    "                              0.004, \n",
    "                              0.005]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414fab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GridSearchCV with the estimator being a DecisionTreeClassifier with a fixed random state.\n",
    "# The scoring metric used here is accuracy\n",
    "grid_search_dt = GridSearchCV(estimator = DecisionTreeClassifier(random_state = 365), \n",
    "                              param_grid = parameters_dt, \n",
    "                              scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a GridSearchCV object on the training data\n",
    "grid_search_dt.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd72b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best estimator after grid search\n",
    "grid_search_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the model with the best parameters to dt_clf\n",
    "dt_clf = grid_search_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1f5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size for the plot\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# Plot the decision tree. Feature names and class names are added for better interpretability\n",
    "plot_tree(dt_clf, \n",
    "          filled=True, \n",
    "          feature_names = ['Days on platform', \n",
    "                           'Minutes watched', \n",
    "                           'Courses started',\n",
    "                           'Practice exams passed', \n",
    "                           'Time spent on exams', \n",
    "                           'Student country encoded'], \n",
    "          class_names = ['Will not purchase', \n",
    "                         'Will purchase'])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6453e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best decision tree model to predict the target variable for the test dataset\n",
    "y_test_pred_dt = dt_clf.predict(x_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a64e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset seaborn settings to default\n",
    "sns.reset_orig()\n",
    "\n",
    "# Display the confusion matrix using seaborn.\n",
    "# Use 'magma' colormap for better visualization\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test_array, y_test_pred_dt,\n",
    "    labels = dt_clf.classes_,\n",
    "    cmap = 'magma'\n",
    ");\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8144a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report to get precision, recall, f1-score, and support for each class\n",
    "print(classification_report(y_test_array, y_test_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95ab9c",
   "metadata": {},
   "source": [
    "# Creating a Random Forests Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5119482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier with ccp_alpha set to 0.0001\n",
    "rf_clf = RandomForestClassifier(ccp_alpha = 0.0001, random_state = 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d59067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the random forest model on the training data\n",
    "rf_clf.fit(x_train_array, y_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb288fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained random forest model to predict the target variable for the test dataset\n",
    "y_test_pred_rf = rf_clf.predict(x_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset seaborn settings to default\n",
    "sns.reset_orig()\n",
    "\n",
    "# Display the confusion matrix using seaborn\n",
    "# Use 'magma' colormap for better visualization\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test_array, y_test_pred_rf,\n",
    "    labels = rf_clf.classes_,\n",
    "    cmap = 'magma' \n",
    ");\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22567b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report to get precision, recall, f1-score, and support for each class\n",
    "print(classification_report(y_test_array, y_test_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "365engagement",
   "language": "python",
   "name": "365engagement"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
