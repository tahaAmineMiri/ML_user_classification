{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "968f6584",
   "metadata": {},
   "source": [
    "# Importing the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df416b8a",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434aead",
   "metadata": {},
   "source": [
    "### Importing the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c620a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from the CSV file\n",
    "raw_data = pd.read_csv('ml_datasource.csv')\n",
    "\n",
    "# Display the first 5 rows of the dataframe for preview\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4580c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ab2c7",
   "metadata": {},
   "source": [
    "### Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset any modifications to the plotting context (sns) made via seaborn\n",
    "sns.reset_orig()\n",
    "\n",
    "# Set the font scale for seaborn plots\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Initialize a grid of plots with specified dimensions\n",
    "fig, axes = plt.subplots(3, 2, figsize=(20,20))\n",
    "\n",
    "# Plotting distribution plots for each of the columns in the dataset\n",
    "sns.kdeplot(data=data['days_on_platform'], ax=axes[0,0])\n",
    "sns.kdeplot(data=data['minutes_watched'], ax=axes[0,1])\n",
    "sns.kdeplot(data=data['courses_started'], ax=axes[1,0])\n",
    "sns.kdeplot(data=data['practice_exams_started'], ax=axes[1,1])\n",
    "sns.kdeplot(data=data['practice_exams_passed'], ax=axes[2,0])\n",
    "sns.kdeplot(data=data['minutes_spent_on_exams'], ax=axes[2,1]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers based on 'minutes_watched', 'courses_started',\n",
    "# and 'practice_exams_started', and 'minutes_spent_on_exams' fields\n",
    "data_no_outliers = data[(data['minutes_watched'] <= 1000)\n",
    "                            & (data['courses_started']<=10)\n",
    "                            & (data['practice_exams_started']<=10)\n",
    "                            & (data['minutes_spent_on_exams']<=40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecce72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset any modifications to the plotting context (sns) made via seaborn\n",
    "sns.reset_orig()\n",
    "\n",
    "# Set the font scale for seaborn plots\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Initialize a grid of plots with specified dimensions\n",
    "fig, axes = plt.subplots(3, 2, figsize=(20,20))\n",
    "\n",
    "# Plotting distribution plots for each of the columns in the dataset\n",
    "sns.kdeplot(data=data_no_outliers['days_on_platform'], ax=axes[0,0])\n",
    "sns.kdeplot(data=data_no_outliers['minutes_watched'], ax=axes[0,1])\n",
    "sns.kdeplot(data=data_no_outliers['courses_started'], ax=axes[1,0])\n",
    "sns.kdeplot(data=data_no_outliers['practice_exams_started'], ax=axes[1,1])\n",
    "sns.kdeplot(data=data_no_outliers['practice_exams_passed'], ax=axes[2,0])\n",
    "sns.kdeplot(data=data_no_outliers['minutes_spent_on_exams'], ax=axes[2,1]);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9cc4a7",
   "metadata": {},
   "source": [
    "### Checking for Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the column names of the dataset (for reference)\n",
    "data_no_outliers.columns.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228bb4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the numerical columns for Variance Inflation Factor (VIF) calculation\n",
    "variables = data_no_outliers[['days_on_platform',\n",
    "                              'minutes_watched',\n",
    "                              'courses_started', \n",
    "                              'practice_exams_started', \n",
    "                              'practice_exams_passed', \n",
    "                              'minutes_spent_on_exams']]\n",
    "\n",
    "# Creating a DataFrame to store the VIF value for each feature\n",
    "vif = pd.DataFrame()\n",
    "\n",
    "# Computing the VIF for each selected feature using list comprehension\n",
    "# Storing the values in a column called 'VIF'\n",
    "vif['VIF'] = [variance_inflation_factor(variables.to_numpy(), i) for i in range(variables.shape[1])]\n",
    "\n",
    "# Storing the names of the features in a column called 'features'\n",
    "vif['features'] = variables.columns\n",
    "\n",
    "# Displaying the DataFrame\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd8ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping 'practice_exams' to prevent multicollinearity \n",
    "data_no_mult = data_no_outliers.drop('practice_exams_started', axis = 1)\n",
    "\n",
    "# Displaying the first five rows of the new data\n",
    "data_no_mult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd54128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specific columns for new Variance Inflation Factor (VIF) calculation\n",
    "variables = data_no_outliers[['days_on_platform',\n",
    "                              'minutes_watched',\n",
    "                              'courses_started', \n",
    "                              'practice_exams_passed', \n",
    "                              'minutes_spent_on_exams']]\n",
    "\n",
    "# Computing the new VIF values for each selected feature\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF\"] = [variance_inflation_factor(variables.to_numpy(), i) for i in range(variables.shape[1])]\n",
    "vif[\"features\"] = variables.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1e168",
   "metadata": {},
   "source": [
    "### Dealing with NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of null values in each column\n",
    "data_no_mult.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a9d87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select rows from the 'data_no_mult' DataFrame where the \n",
    "# 'student_country' column has missing values (NaN).\n",
    "data_no_mult.loc[ data_no_mult['student_country'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b231a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing NaN values with the string 'NAM'\n",
    "data_no_nulls = data_no_mult.fillna('NAM', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c691c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying records where 'student_country' is 'NAM'\n",
    "data_no_nulls.loc[ data_no_nulls['student_country'] == 'NAM', 'student_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-checking the number of null values in each column after replacement\n",
    "data_no_nulls.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c7040a",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b8b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining inputs (feature variables) and target (outcome variable)\n",
    "inputs = data_no_nulls.drop(['purchased'],axis=1)\n",
    "target = data_no_nulls['purchased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets, ensuring balanced classes with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, \n",
    "                                                    target, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=365,\n",
    "                                                    stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the DataFrame for preview\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced87b59",
   "metadata": {},
   "source": [
    "### Encoding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c5791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing an ordinal encoder for categorical variables\n",
    "enc = OrdinalEncoder(handle_unknown = 'use_encoded_value', \n",
    "                     unknown_value = 170);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3790879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the 'student_country' column in the training and testing datasets\n",
    "# and storing the encoded variable in a new column called 'student_country_enc'\n",
    "x_train['student_country_enc'] = enc.fit_transform(x_train['student_country'].to_numpy().reshape(-1, 1));\n",
    "x_test['student_country_enc'] = enc.transform(x_test['student_country'].to_numpy().reshape(-1, 1));\n",
    "\n",
    "# Dropping the original 'student_country' column after encoding\n",
    "x_train = x_train.drop('student_country', axis = 1)\n",
    "x_test = x_test.drop('student_country', axis = 1)\n",
    "\n",
    "# Displaying the first five rows of the encoded training dataset\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbc3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the np.asarray() method to ensure data type consistency and compatibility.\n",
    "# y_train values are converted to integers and x_train values are converted to floating-point numbers.\n",
    "\n",
    "x_train_array = np.asarray(x_train, dtype = 'float')\n",
    "y_train_array = np.asarray(y_train, dtype = 'int')\n",
    "\n",
    "x_test_array = np.asarray(x_test, dtype = 'float')\n",
    "y_test_array = np.asarray(y_test, dtype = 'int')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "365engagement",
   "language": "python",
   "name": "365engagement"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
